<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"></head><body class="c27 c60"><h1 class="c45 c10" id="h.sl8q8y4gq0tb"><span class="c19">CarND-Path-Planning-Project</span></h1><h1 class="c10 c45" id="h.3gc3ewas5i1j"><span class="c19">Semantic Segmentation</span></h1><h3 class="c10 c15" id="h.ihhrvp3uctp9"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 576.00px; height: 160.00px;"><img alt="" src="images/image8.png" style="width: 576.00px; height: 160.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></h3><h3 class="c15 c10" id="h.fjg11umz0i8q"><span class="c33">Introduction</span></h3><p class="c32 c10"><span class="c22 c21">In this project, you&#39;ll label the pixels of a road in images using a Fully Convolutional Network (FCN).</span></p><h3 class="c15 c10" id="h.ch0qbzojsdsi"><span class="c33">Setup</span></h3><h3 class="c15 c10" id="h.kmmkbog2bz1y"><span class="c22 c43">Frameworks and Packages</span></h3><p class="c32 c10"><span class="c22 c21">Make sure you have the following is installed:</span></p><ul class="c34 lst-kix_1rj01lbgs74w-0 start"><li class="c32 c10 c53"><span class="c18 c46"><a class="c7" href="https://www.google.com/url?q=https://www.python.org/&amp;sa=D&amp;ust=1522392474924000">Python 3</a></span></li><li class="c24 c10"><span class="c18 c46"><a class="c7" href="https://www.google.com/url?q=https://www.tensorflow.org/&amp;sa=D&amp;ust=1522392474924000">TensorFlow</a></span></li><li class="c24 c10"><span class="c18 c46"><a class="c7" href="https://www.google.com/url?q=http://www.numpy.org/&amp;sa=D&amp;ust=1522392474924000">NumPy</a></span></li><li class="c10 c24"><span class="c18 c46"><a class="c7" href="https://www.google.com/url?q=https://www.scipy.org/&amp;sa=D&amp;ust=1522392474925000">SciPy</a></span></li></ul><h3 class="c15 c10" id="h.h67a7u9i51oy"><span class="c22 c43">Dataset</span></h3><p class="c32 c10"><span class="c21">Download the </span><span class="c18"><a class="c7" href="https://www.google.com/url?q=http://www.cvlibs.net/datasets/kitti/eval_road.php&amp;sa=D&amp;ust=1522392474925000">Kitti Road dataset</a></span><span class="c21">&nbsp;from </span><span class="c18"><a class="c7" href="https://www.google.com/url?q=http://www.cvlibs.net/download.php?file%3Ddata_road.zip&amp;sa=D&amp;ust=1522392474925000">here</a></span><span class="c21">. Extract the dataset in the </span><span class="c6">data</span><span class="c21">&nbsp;folder. This will create the folder </span><span class="c6">data_road</span><span class="c22 c21">&nbsp;with all the training a test images.</span></p><h2 class="c15 c10" id="h.hu03jrh0lj2d"><span class="c30 c51">Run</span></h2><p class="c32 c10"><span class="c22 c21">Run the following command to run the project:</span></p><p class="c10 c25"><span class="c6 c29">python main.py</span></p><p class="c4"><span>To run this code you would need a GPU with at least 6GB of memory, because I did not have one with me I used </span><span class="c49"><a class="c7" href="https://www.google.com/url?q=http://www.floydhub.com&amp;sa=D&amp;ust=1522392474926000">floyhub</a></span><span class="c9">.</span></p><p class="c3"><span class="c9"></span></p><p class="c4"><span class="c9">To run the project under floydhub type this line in your command line after you upload your data road dataset and vgg model:</span></p><p class="c3"><span class="c9"></span></p><p class="c4"><span class="c9">floyd run --gpu --env tensorflow-1.3 --data USERNAME/datasets/data_road/1:/data_road</span></p><p class="c4"><span class="c9">--data USERNAME/datasets/pretrained_vgg/1:/pretrained_vgg &quot;python main.py&quot;</span></p><p class="c10 c12"><span class="c6 c29"></span></p><h3 class="c10 c62" id="h.71c4ih173a6"><span class="c51 c43">Results</span></h3><p class="c4 c10"><span class="c38">Does the project load the pretrained vgg model?</span></p><p class="c4 c10"><span>F</span><span class="c9">unction load_vgg is implemented correctly to load (see main.py ln54). It loads the model VGG from a SavedModel as specified by &nbsp;tags &lsquo;vgg16&rsquo; and it saves it in the specified path vgg_path and with tf.get_default_graph() we get the graph with the loaded context.</span></p><p class="c3 c10"><span class="c9"></span></p><a id="t.07784d1a38f72da83207b77d2dcfb0b6fd063d4c"></a><a id="t.0"></a><table class="c10 c31"><tbody><tr class="c17"><td class="c23" colspan="1" rowspan="1"><p class="c4 c10"><span class="c5">tf.saved_model.loader.load(sess</span><span class="c0">, </span><span class="c5">[</span><span class="c42">&#39;vgg16&#39;</span><span class="c5">]</span><span class="c0">, </span><span class="c2">vgg_path)</span></p><p class="c4 c10"><span class="c2">graph = tf.get_default_graph()</span></p><p class="c3 c10"><span class="c2"></span></p><p class="c4 c10"><span class="c5">image_input = graph.get_tensor_by_name(</span><span class="c42">&#39;image_input:0&#39;</span><span class="c2">)</span></p><p class="c4 c10"><span class="c5">keep_prob = graph.get_tensor_by_name(</span><span class="c42">&#39;keep_prob:0&#39;</span><span class="c2">)</span></p><p class="c4 c10"><span class="c5">layer3_out = graph.get_tensor_by_name(</span><span class="c42">&#39;layer3_out:0&#39;</span><span class="c2">)</span></p><p class="c4 c10"><span class="c5">layer4_out = graph.get_tensor_by_name(</span><span class="c42">&#39;layer4_out:0&#39;</span><span class="c2">)</span></p><p class="c4 c10"><span class="c5">layer7_out = graph.get_tensor_by_name(</span><span class="c42">&#39;layer7_out:0&#39;</span><span class="c5">)</span></p></td></tr></tbody></table><p class="c3"><span class="c9"></span></p><p class="c4 c10"><span class="c38">Does the project learn the correct features from the images?</span></p><p class="c4"><span>The function layers is implemented correctly(see main.py ln78) as specified in the </span><span class="c49"><a class="c7" href="https://www.google.com/url?q=https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf&amp;sa=D&amp;ust=1522392474929000">Fully Convolutional Networks for Semantic Segmentation</a></span><span class="c9">. In order for weights to be transposed convolution layers &nbsp;are implemented using tf.layers.conv2d. After a transpose layer I applied a skip technique by adding to the output of the upper layer. The purpose of the transpose layer to match upper layer shape so I can merge weights using tf.add. </span></p><a id="t.eed9f02870b85317a8244927041917418a942c06"></a><a id="t.1"></a><table class="c31 c10"><tbody><tr class="c17"><td class="c40" colspan="1" rowspan="1"><p class="c4 c10"><span class="c5">kernel_initializer = tf.truncated_normal_initializer(</span><span class="c8">stddev</span><span class="c5">=</span><span class="c36">self</span><span class="c5">.init_sd)</span></p><p class="c4 c10"><span class="c20"># 1x1 convolutions of the three layers</span></p><p class="c4 c10"><span class="c5">conv_7 = tf.layers.conv2d(vgg_layer7_out</span><span class="c0">, </span><span class="c5">num_classes</span><span class="c0">, </span><span class="c11">1</span><span class="c0">, </span><span class="c11">1</span><span class="c0">, &nbsp;</span><span class="c8">kernel_initializer</span><span class="c5">=kernel_initializer</span><span class="c0">, </span><span class="c8">kernel_regularizer</span><span class="c2">=kernel_regularizer)</span></p><p class="c4 c10"><span class="c5">conv_4 = tf.layers.conv2d(vgg_layer4_out</span><span class="c0">, </span><span class="c5">num_classes</span><span class="c0">, </span><span class="c11">1</span><span class="c0">, </span><span class="c11">1</span><span class="c22 c0">,</span></p><p class="c4 c10"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c8">kernel_initializer</span><span class="c5">=kernel_initializer</span><span class="c0">, </span><span class="c8">kernel_regularizer</span><span class="c2">=kernel_regularizer)</span></p><p class="c4 c10"><span class="c5">conv_3 = tf.layers.conv2d(vgg_layer3_out</span><span class="c0">, </span><span class="c5">num_classes</span><span class="c0">, </span><span class="c11">1</span><span class="c0">, </span><span class="c11">1</span><span class="c22 c0">,</span></p><p class="c4 c10"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c8">kernel_initializer</span><span class="c5">=kernel_initializer</span><span class="c0">, </span><span class="c8">kernel_regularizer</span><span class="c2">=kernel_regularizer)</span></p><p class="c3 c10"><span class="c2"></span></p><p class="c4"><span class="c52">&nbsp;</span><span class="c22 c52"># Upsample layer 7 and add to layer 4</span></p><p class="c4 c10"><span class="c20"># tf.layers.conv2d_transpose(inputs,filters,kernel_size,strides=(1, 1), padding=&#39;valid&#39;...)</span></p><p class="c4 c10"><span class="c5">input = tf.layers.conv2d_transpose(conv_7</span><span class="c0">, </span><span class="c5">num_classes</span><span class="c0">, </span><span class="c11">4</span><span class="c0">, </span><span class="c11">2</span><span class="c0">, </span><span class="c42">&#39;SAME&#39;</span><span class="c0 c22">,</span></p><p class="c4 c10"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c8">kernel_initializer</span><span class="c5">=kernel_initializer</span><span class="c0">, </span><span class="c8">kernel_regularizer</span><span class="c2">=kernel_regularizer)</span></p><p class="c4 c10"><span class="c5">input = tf.add(input</span><span class="c0">, </span><span class="c2">conv_4)</span></p><p class="c3 c10"><span class="c2"></span></p><p class="c4 c10"><span class="c20"># add to layer 3</span></p><p class="c4 c10"><span class="c5">input = tf.layers.conv2d_transpose(input</span><span class="c0">, </span><span class="c5">num_classes</span><span class="c0">, </span><span class="c11">4</span><span class="c0">, </span><span class="c11">2</span><span class="c0">, </span><span class="c42">&#39;SAME&#39;</span><span class="c22 c0">,</span></p><p class="c4 c10"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c8">kernel_initializer</span><span class="c5">=kernel_initializer</span><span class="c0">, </span><span class="c8">kernel_regularizer</span><span class="c2">=kernel_regularizer)</span></p><p class="c4 c10"><span class="c5">input = tf.add(input</span><span class="c0">, </span><span class="c2">conv_3)</span></p><p class="c3 c10"><span class="c2"></span></p><p class="c4 c10"><span class="c20"># Upsample the input and return</span></p><p class="c4 c10"><span class="c5">input = tf.layers.conv2d_transpose(input</span><span class="c0">, </span><span class="c5">num_classes</span><span class="c0">, </span><span class="c11">16</span><span class="c0">, </span><span class="c11">8</span><span class="c0">, </span><span class="c42">&#39;SAME&#39;</span><span class="c22 c0">,</span></p><p class="c4 c10"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c8">kernel_initializer</span><span class="c5">=kernel_initializer</span><span class="c0">, </span><span class="c8">kernel_regularizer</span><span class="c5">=kernel_regularizer)</span></p></td></tr><tr class="c17"><td class="c40" colspan="1" rowspan="1"><p class="c3"><span class="c2"></span></p></td></tr></tbody></table><p class="c3 c10"><span class="c9"></span></p><p class="c3 c10"><span class="c2"></span></p><p class="c4"><span class="c9">To smooth out on the edges pixels I ran a series of test with kernel_regularizer and &nbsp;kernel_initializer. And as you can see in the images bellow kernel_regularizer did slightly better. </span></p><p class="c3"><span class="c2"></span></p><a id="t.e95b87504afaff215cb1e04a22cfcd5c6b8efa64"></a><a id="t.2"></a><table class="c31 c59"><tbody><tr class="c50"><td class="c16" colspan="2" rowspan="1"><p class="c13 c44"><span class="c9">The following images were taking at 30 epoch just to identified a good way to smooth pixel on the edges. The real training model was trained with 100 epochs </span></p></td></tr><tr class="c17"><td class="c39" colspan="1" rowspan="1"><p class="c13 c44"><span class="c9">With regularizer, no kernel_initialize</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c13 c44"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 525.56px; height: 146.50px;"><img alt="" src="images/image7.png" style="width: 525.56px; height: 146.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c35"><td class="c39" colspan="1" rowspan="1"><p class="c13 c44"><span>With regularizer and kernel_initializer </span><span class="c48">vector norms</span><span class="c9">. </span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c13 c10"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 513.00px; height: 142.67px;"><img alt="" src="images/image5.png" style="width: 513.00px; height: 142.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c35"><td class="c39" colspan="1" rowspan="1"><p class="c13 c44"><span>With kernel_initialize with </span><span class="c48">vector norms</span><span class="c9">, no regularizer</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c13 c10"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 513.00px; height: 142.67px;"><img alt="" src="images/image4.png" style="width: 513.00px; height: 142.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr></tbody></table><p class="c3 c10"><span class="c2"></span></p><p class="c3 c10"><span class="c9"></span></p><p class="c3 c10"><span class="c9"></span></p><p class="c4 c10"><span class="c38">Does the project optimize the neural network?</span></p><p class="c4 c10"><span>The function optimize is implemented correctly. </span><span class="c22 c21 c27">We compute the softmax cross entropy between logits and labels and use an Adam algorithm optimizer to minimize the cross entropy loss.</span></p><p class="c3 c10"><span class="c22 c21 c27"></span></p><a id="t.37483edd5c864963827a6c5c12b6813bdded772a"></a><a id="t.3"></a><table class="c31 c10"><tbody><tr class="c17"><td class="c54" colspan="1" rowspan="1"><p class="c4 c10"><span class="c20"># Reshape logits for computing cross entropy</span></p><p class="c4 c10"><span class="c5">logits = tf.reshape(nn_last_layer</span><span class="c0">, </span><span class="c5">(-</span><span class="c11">1</span><span class="c0">, </span><span class="c5">num_classes)</span><span class="c0">, </span><span class="c8">name</span><span class="c5">=</span><span class="c42">&#39;logits&#39;</span><span class="c2">)</span></p><p class="c3 c10"><span class="c2"></span></p><p class="c4 c10"><span class="c20"># Compute cross entropy and loss</span></p><p class="c4 c10"><span class="c5">cross_entropy_logits = tf.nn.softmax_cross_entropy_with_logits(</span><span class="c8">logits</span><span class="c5">=logits</span><span class="c0">, </span><span class="c8">labels</span><span class="c2">=correct_label)</span></p><p class="c3 c10"><span class="c2"></span></p><p class="c4 c10"><span class="c20"># All regularization terms are added to a collection called tf.GraphKeys.REGULARIZATION_LOSSES,</span></p><p class="c4 c10"><span class="c20"># add the sum of all regularization losses to the previously calculated cross-entropy</span></p><p class="c4 c10"><span class="c5">cross_entropy_loss = tf.reduce_mean(cross_entropy_logits) + &nbsp;</span><span class="c47">sum</span><span class="c2">(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))</span></p><p class="c3 c10"><span class="c2"></span></p><p class="c4 c10"><span class="c20"># Training operation using the Adam optimizer</span></p><p class="c4 c10"><span class="c2">train_op = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy_loss)</span></p><p class="c3 c10"><span class="c20"></span></p></td></tr></tbody></table><p class="c3 c10"><span class="c22 c21 c27"></span></p><p class="c3"><span class="c9"></span></p><p class="c4 c10"><span class="c38">Does the project train the neural network?</span></p><p class="c4 c10"><span class="c9">The function train_nn is implemented correctly. The loss of the network is as shown below is printed while the network is training.</span></p><p class="c3 c10"><span class="c9"></span></p><a id="t.2cbd3d60fd395ef4a591027008d1b3b2a544b4d4"></a><a id="t.4"></a><table class="c31 c41"><tbody><tr class="c17"><td class="c57" colspan="1" rowspan="1"><p class="c13 c10"><span class="c9">Below you can see the loss decreasing </span></p></td></tr><tr class="c17"><td class="c57" colspan="1" rowspan="1"><p class="c4 c10"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 205.03px; height: 305.50px;"><img alt="" src="images/image6.png" style="width: 205.03px; height: 305.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr></tbody></table><p class="c44 c56 c58"><span class="c22 c55"></span></p><p class="c4 c10"><span class="c38">Does the project train the model correctly?</span></p><p class="c4 c10"><span class="c9">On average, the model decreases loss over time</span></p><p class="c3 c10"><span class="c9"></span></p><p class="c4 c10"><span class="c9">Does the project use reasonable hyperparameters?</span></p><p class="c10 c32"><span class="c21">In my case the optimal epoch I found with my model perform better using a batch size of 10 and loose was did not reduced after 100 epochs. </span></p><p class="c3 c10"><span class="c9"></span></p><p class="c4 c10"><span class="c38">Does the project correctly label the road?</span></p><p class="c4 c10"><span class="c9">The project labels most pixels of roads close to the best solution. The model doesn&#39;t have to predict correctly all the images, just most of them. As you can see in the images bellow this model is labeling more than 80% of the road and label no more than 20% of non-road pixels as road. </span></p><p class="c3 c10"><span class="c9"></span></p><a id="t.34c968869fbbdaac8fff0fec79919d98042a1192"></a><a id="t.5"></a><table class="c31 c10"><tbody><tr class="c17"><td class="c28" colspan="1" rowspan="1"><p class="c13"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 373.00px; height: 104.00px;"><img alt="" src="images/image2.png" style="width: 373.00px; height: 104.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c13"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 373.00px; height: 104.00px;"><img alt="" src="images/image9.png" style="width: 373.00px; height: 104.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c17"><td class="c28" colspan="1" rowspan="1"><p class="c13"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 373.00px; height: 104.00px;"><img alt="" src="images/image3.png" style="width: 373.00px; height: 104.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c13"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 373.00px; height: 104.00px;"><img alt="" src="images/image1.png" style="width: 373.00px; height: 104.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr></tbody></table><p class="c3 c10"><span class="c9"></span></p><p class="c3 c10"><span class="c9"></span></p><hr><p class="c12 c10"><span class="c6 c29"></span></p><p class="c12 c10"><span class="c6 c29"></span></p><p class="c10 c14"><span class="c22 c21"></span></p><h2 class="c10 c26" id="h.kpumfxhu7sl8"><span class="c22 c30">References:</span></h2><ul class="c34 lst-kix_a102oay53e4d-0 start"><li class="c4 c37"><span>Udacity Self-Driving Car <br>The link for the frozen VGG16 model is hardcoded into helper.py. The model can be found </span><span class="c49 c46 c61"><a class="c7" href="https://www.google.com/url?q=https://s3-us-west-1.amazonaws.com/udacity-selfdrivingcar/vgg.zip&amp;sa=D&amp;ust=1522392474943000">here</a></span></li><li class="c4 c37"><span>The model is not vanilla VGG16, but a fully convolutional version, which already contains the 1x1 convolutions to replace the fully connected layers. Please see this </span><span class="c49"><a class="c7" href="https://www.google.com/url?q=https://discussions.udacity.com/t/here-is-some-advice-and-clarifications-about-the-semantic-segmentation-project/403100/8?u%3Dsubodh.malgonde&amp;sa=D&amp;ust=1522392474944000">forum post</a></span><span class="c9">&nbsp;for more information. A summary of additional points, follow.</span></li><li class="c4 c37"><span class="c9">The original FCN-8s was trained in stages. The authors later uploaded a version that was trained all at once to their GitHub repo. The version in the GitHub repo has one important difference: The outputs of pooling layers 3 and 4 are scaled before they are fed into the 1x1 convolutions. As a result, some students have found that the model learns much better with the scaling layers included. The model may not converge substantially faster, but may reach a higher IoU and accuracy.</span></li><li class="c4 c37"><span class="c9">When adding l2-regularization, setting a regularizer in the arguments of the tf.layers is not enough. Regularization loss terms must be manually added to your loss function. otherwise regularization is not implemented.</span></li></ul><p class="c3 c10"><span><br></span></p></body></html>