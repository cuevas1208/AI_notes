<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url('https://themes.googleusercontent.com/fonts/css?kit=pYEwJuzr3ZMDX2Y1syVbvx06if6osnyAslCuLPPf50A');ol.lst-kix_sxslfcnktzg1-1{list-style-type:none}ol.lst-kix_sxslfcnktzg1-2{list-style-type:none}ol.lst-kix_sxslfcnktzg1-0{list-style-type:none}ol.lst-kix_sxslfcnktzg1-5{list-style-type:none}ol.lst-kix_sxslfcnktzg1-6{list-style-type:none}ol.lst-kix_sxslfcnktzg1-3{list-style-type:none}ol.lst-kix_sxslfcnktzg1-4{list-style-type:none}ol.lst-kix_sxslfcnktzg1-7{list-style-type:none}ol.lst-kix_sxslfcnktzg1-8{list-style-type:none}.lst-kix_pmz5s3rqvha4-7>li{counter-increment:lst-ctn-kix_pmz5s3rqvha4-7}ol.lst-kix_sxslfcnktzg1-7.start{counter-reset:lst-ctn-kix_sxslfcnktzg1-7 0}ol.lst-kix_pmz5s3rqvha4-4.start{counter-reset:lst-ctn-kix_pmz5s3rqvha4-4 0}.lst-kix_sxslfcnktzg1-0>li{counter-increment:lst-ctn-kix_sxslfcnktzg1-0}.lst-kix_vocg9dsh5o45-2>li:before{content:"\0025a0  "}.lst-kix_vocg9dsh5o45-3>li:before{content:"\0025cf  "}.lst-kix_vocg9dsh5o45-0>li:before{content:"\0025cf  "}.lst-kix_vocg9dsh5o45-8>li:before{content:"\0025a0  "}.lst-kix_vocg9dsh5o45-1>li:before{content:"\0025cb  "}.lst-kix_vocg9dsh5o45-7>li:before{content:"\0025cb  "}.lst-kix_vocg9dsh5o45-6>li:before{content:"\0025cf  "}.lst-kix_vocg9dsh5o45-4>li:before{content:"\0025cb  "}.lst-kix_vocg9dsh5o45-5>li:before{content:"\0025a0  "}ol.lst-kix_sxslfcnktzg1-2.start{counter-reset:lst-ctn-kix_sxslfcnktzg1-2 0}ul.lst-kix_a102oay53e4d-5{list-style-type:none}ul.lst-kix_a102oay53e4d-6{list-style-type:none}ul.lst-kix_a102oay53e4d-3{list-style-type:none}ul.lst-kix_a102oay53e4d-4{list-style-type:none}ul.lst-kix_a102oay53e4d-1{list-style-type:none}ul.lst-kix_a102oay53e4d-2{list-style-type:none}ul.lst-kix_a102oay53e4d-0{list-style-type:none}ul.lst-kix_a102oay53e4d-7{list-style-type:none}ul.lst-kix_a102oay53e4d-8{list-style-type:none}ol.lst-kix_sxslfcnktzg1-8.start{counter-reset:lst-ctn-kix_sxslfcnktzg1-8 0}ol.lst-kix_sxslfcnktzg1-1.start{counter-reset:lst-ctn-kix_sxslfcnktzg1-1 0}.lst-kix_sxslfcnktzg1-4>li{counter-increment:lst-ctn-kix_sxslfcnktzg1-4}ul.lst-kix_1rj01lbgs74w-8{list-style-type:none}ul.lst-kix_1rj01lbgs74w-7{list-style-type:none}ul.lst-kix_1rj01lbgs74w-4{list-style-type:none}ul.lst-kix_1rj01lbgs74w-3{list-style-type:none}ul.lst-kix_1rj01lbgs74w-6{list-style-type:none}ul.lst-kix_1rj01lbgs74w-5{list-style-type:none}ul.lst-kix_1rj01lbgs74w-0{list-style-type:none}ul.lst-kix_1rj01lbgs74w-2{list-style-type:none}.lst-kix_y58mt09ypq8c-2>li:before{content:"\0025a0  "}.lst-kix_y58mt09ypq8c-4>li:before{content:"\0025cb  "}ul.lst-kix_1rj01lbgs74w-1{list-style-type:none}.lst-kix_pmz5s3rqvha4-1>li{counter-increment:lst-ctn-kix_pmz5s3rqvha4-1}.lst-kix_sxslfcnktzg1-3>li{counter-increment:lst-ctn-kix_sxslfcnktzg1-3}ol.lst-kix_pmz5s3rqvha4-0.start{counter-reset:lst-ctn-kix_pmz5s3rqvha4-0 0}.lst-kix_y58mt09ypq8c-0>li:before{content:"\0025cf  "}ul.lst-kix_byq40nhaw2di-7{list-style-type:none}ul.lst-kix_byq40nhaw2di-6{list-style-type:none}ul.lst-kix_byq40nhaw2di-5{list-style-type:none}ul.lst-kix_byq40nhaw2di-4{list-style-type:none}ul.lst-kix_byq40nhaw2di-3{list-style-type:none}ul.lst-kix_byq40nhaw2di-2{list-style-type:none}ul.lst-kix_byq40nhaw2di-1{list-style-type:none}ul.lst-kix_byq40nhaw2di-0{list-style-type:none}ol.lst-kix_sxslfcnktzg1-0.start{counter-reset:lst-ctn-kix_sxslfcnktzg1-0 0}.lst-kix_y58mt09ypq8c-6>li:before{content:"\0025cf  "}.lst-kix_sxslfcnktzg1-5>li{counter-increment:lst-ctn-kix_sxslfcnktzg1-5}ul.lst-kix_byq40nhaw2di-8{list-style-type:none}.lst-kix_pmz5s3rqvha4-3>li{counter-increment:lst-ctn-kix_pmz5s3rqvha4-3}.lst-kix_y58mt09ypq8c-8>li:before{content:"\0025a0  "}.lst-kix_sxslfcnktzg1-3>li:before{content:"" counter(lst-ctn-kix_sxslfcnktzg1-3,decimal) ". "}.lst-kix_sxslfcnktzg1-5>li:before{content:"" counter(lst-ctn-kix_sxslfcnktzg1-5,lower-roman) ". "}.lst-kix_sxslfcnktzg1-1>li:before{content:"" counter(lst-ctn-kix_sxslfcnktzg1-1,lower-latin) ". "}ul.lst-kix_vocg9dsh5o45-5{list-style-type:none}ul.lst-kix_vocg9dsh5o45-6{list-style-type:none}ul.lst-kix_vocg9dsh5o45-7{list-style-type:none}ul.lst-kix_vocg9dsh5o45-8{list-style-type:none}ul.lst-kix_vocg9dsh5o45-1{list-style-type:none}ul.lst-kix_vocg9dsh5o45-2{list-style-type:none}ul.lst-kix_vocg9dsh5o45-3{list-style-type:none}.lst-kix_pmz5s3rqvha4-7>li:before{content:"" counter(lst-ctn-kix_pmz5s3rqvha4-7,lower-latin) ". "}ul.lst-kix_vocg9dsh5o45-4{list-style-type:none}.lst-kix_byq40nhaw2di-0>li:before{content:"\0025cf  "}ul.lst-kix_vocg9dsh5o45-0{list-style-type:none}.lst-kix_a102oay53e4d-7>li:before{content:"\0025cb  "}.lst-kix_byq40nhaw2di-2>li:before{content:"\0025a0  "}.lst-kix_byq40nhaw2di-4>li:before{content:"\0025cb  "}.lst-kix_pmz5s3rqvha4-2>li{counter-increment:lst-ctn-kix_pmz5s3rqvha4-2}.lst-kix_pmz5s3rqvha4-8>li{counter-increment:lst-ctn-kix_pmz5s3rqvha4-8}.lst-kix_byq40nhaw2di-6>li:before{content:"\0025cf  "}.lst-kix_pmz5s3rqvha4-5>li:before{content:"" counter(lst-ctn-kix_pmz5s3rqvha4-5,lower-roman) ". "}.lst-kix_pmz5s3rqvha4-3>li:before{content:"" counter(lst-ctn-kix_pmz5s3rqvha4-3,decimal) ". "}.lst-kix_byq40nhaw2di-8>li:before{content:"\0025a0  "}.lst-kix_sxslfcnktzg1-7>li:before{content:"" counter(lst-ctn-kix_sxslfcnktzg1-7,lower-latin) ". "}.lst-kix_pmz5s3rqvha4-1>li:before{content:"" counter(lst-ctn-kix_pmz5s3rqvha4-1,lower-latin) ". "}.lst-kix_qibn6ao0a1s7-8>li:before{content:"\0025a0  "}.lst-kix_qibn6ao0a1s7-6>li:before{content:"\0025cf  "}ul.lst-kix_y58mt09ypq8c-4{list-style-type:none}ul.lst-kix_y58mt09ypq8c-5{list-style-type:none}ul.lst-kix_y58mt09ypq8c-6{list-style-type:none}ul.lst-kix_y58mt09ypq8c-7{list-style-type:none}ul.lst-kix_y58mt09ypq8c-0{list-style-type:none}ol.lst-kix_sxslfcnktzg1-4.start{counter-reset:lst-ctn-kix_sxslfcnktzg1-4 0}ul.lst-kix_y58mt09ypq8c-1{list-style-type:none}.lst-kix_qibn6ao0a1s7-7>li:before{content:"\0025cb  "}ul.lst-kix_y58mt09ypq8c-2{list-style-type:none}ol.lst-kix_pmz5s3rqvha4-7.start{counter-reset:lst-ctn-kix_pmz5s3rqvha4-7 0}ul.lst-kix_y58mt09ypq8c-3{list-style-type:none}.lst-kix_qibn6ao0a1s7-2>li:before{content:"\0025a0  "}.lst-kix_qibn6ao0a1s7-0>li:before{content:"\0025cf  "}.lst-kix_qibn6ao0a1s7-4>li:before{content:"\0025cb  "}.lst-kix_qibn6ao0a1s7-1>li:before{content:"\0025cb  "}.lst-kix_qibn6ao0a1s7-5>li:before{content:"\0025a0  "}.lst-kix_qibn6ao0a1s7-3>li:before{content:"\0025cf  "}.lst-kix_a102oay53e4d-1>li:before{content:"\0025cb  "}.lst-kix_a102oay53e4d-0>li:before{content:"\0025cf  "}.lst-kix_a102oay53e4d-2>li:before{content:"\0025a0  "}.lst-kix_a102oay53e4d-5>li:before{content:"\0025a0  "}.lst-kix_a102oay53e4d-4>li:before{content:"\0025cb  "}.lst-kix_a102oay53e4d-3>li:before{content:"\0025cf  "}ol.lst-kix_pmz5s3rqvha4-1.start{counter-reset:lst-ctn-kix_pmz5s3rqvha4-1 0}ul.lst-kix_qibn6ao0a1s7-0{list-style-type:none}ul.lst-kix_qibn6ao0a1s7-2{list-style-type:none}ul.lst-kix_qibn6ao0a1s7-1{list-style-type:none}ul.lst-kix_qibn6ao0a1s7-4{list-style-type:none}.lst-kix_sxslfcnktzg1-8>li{counter-increment:lst-ctn-kix_sxslfcnktzg1-8}ul.lst-kix_qibn6ao0a1s7-3{list-style-type:none}ul.lst-kix_qibn6ao0a1s7-6{list-style-type:none}ul.lst-kix_qibn6ao0a1s7-5{list-style-type:none}ul.lst-kix_qibn6ao0a1s7-8{list-style-type:none}.lst-kix_pmz5s3rqvha4-6>li{counter-increment:lst-ctn-kix_pmz5s3rqvha4-6}ul.lst-kix_qibn6ao0a1s7-7{list-style-type:none}ul.lst-kix_xdasi2krd8wx-2{list-style-type:none}.lst-kix_1rj01lbgs74w-5>li:before{content:"\0025a0  "}.lst-kix_1rj01lbgs74w-6>li:before{content:"\0025cf  "}ul.lst-kix_xdasi2krd8wx-3{list-style-type:none}ul.lst-kix_xdasi2krd8wx-4{list-style-type:none}ul.lst-kix_xdasi2krd8wx-5{list-style-type:none}ul.lst-kix_xdasi2krd8wx-0{list-style-type:none}ul.lst-kix_xdasi2krd8wx-1{list-style-type:none}.lst-kix_1rj01lbgs74w-1>li:before{content:"\0025cb  "}ul.lst-kix_xdasi2krd8wx-6{list-style-type:none}.lst-kix_1rj01lbgs74w-0>li:before{content:"\0025cf  "}.lst-kix_1rj01lbgs74w-7>li:before{content:"\0025cb  "}.lst-kix_1rj01lbgs74w-8>li:before{content:"\0025a0  "}ul.lst-kix_xdasi2krd8wx-7{list-style-type:none}ul.lst-kix_xdasi2krd8wx-8{list-style-type:none}ol.lst-kix_pmz5s3rqvha4-8.start{counter-reset:lst-ctn-kix_pmz5s3rqvha4-8 0}.lst-kix_pmz5s3rqvha4-4>li{counter-increment:lst-ctn-kix_pmz5s3rqvha4-4}.lst-kix_sxslfcnktzg1-6>li{counter-increment:lst-ctn-kix_sxslfcnktzg1-6}ol.lst-kix_pmz5s3rqvha4-5{list-style-type:none}ol.lst-kix_pmz5s3rqvha4-6{list-style-type:none}ol.lst-kix_pmz5s3rqvha4-3{list-style-type:none}ol.lst-kix_pmz5s3rqvha4-4{list-style-type:none}.lst-kix_xdasi2krd8wx-7>li:before{content:"\0025cb  "}ol.lst-kix_pmz5s3rqvha4-7{list-style-type:none}ol.lst-kix_pmz5s3rqvha4-8{list-style-type:none}.lst-kix_xdasi2krd8wx-4>li:before{content:"\0025cb  "}.lst-kix_xdasi2krd8wx-8>li:before{content:"\0025a0  "}ol.lst-kix_pmz5s3rqvha4-2.start{counter-reset:lst-ctn-kix_pmz5s3rqvha4-2 0}.lst-kix_xdasi2krd8wx-5>li:before{content:"\0025a0  "}ol.lst-kix_pmz5s3rqvha4-1{list-style-type:none}ol.lst-kix_pmz5s3rqvha4-2{list-style-type:none}ol.lst-kix_pmz5s3rqvha4-0{list-style-type:none}.lst-kix_xdasi2krd8wx-6>li:before{content:"\0025cf  "}.lst-kix_xdasi2krd8wx-1>li:before{content:"\0025cb  "}ul.lst-kix_y58mt09ypq8c-8{list-style-type:none}.lst-kix_xdasi2krd8wx-0>li:before{content:"\0025cf  "}.lst-kix_1rj01lbgs74w-2>li:before{content:"\0025a0  "}.lst-kix_xdasi2krd8wx-3>li:before{content:"\0025cf  "}.lst-kix_1rj01lbgs74w-3>li:before{content:"\0025cf  "}.lst-kix_1rj01lbgs74w-4>li:before{content:"\0025cb  "}.lst-kix_xdasi2krd8wx-2>li:before{content:"\0025a0  "}ol.lst-kix_pmz5s3rqvha4-3.start{counter-reset:lst-ctn-kix_pmz5s3rqvha4-3 0}.lst-kix_y58mt09ypq8c-3>li:before{content:"\0025cf  "}.lst-kix_y58mt09ypq8c-1>li:before{content:"\0025cb  "}.lst-kix_y58mt09ypq8c-5>li:before{content:"\0025a0  "}.lst-kix_sxslfcnktzg1-2>li{counter-increment:lst-ctn-kix_sxslfcnktzg1-2}.lst-kix_pmz5s3rqvha4-0>li{counter-increment:lst-ctn-kix_pmz5s3rqvha4-0}ol.lst-kix_sxslfcnktzg1-3.start{counter-reset:lst-ctn-kix_sxslfcnktzg1-3 0}.lst-kix_y58mt09ypq8c-7>li:before{content:"\0025cb  "}ol.lst-kix_sxslfcnktzg1-6.start{counter-reset:lst-ctn-kix_sxslfcnktzg1-6 0}.lst-kix_sxslfcnktzg1-4>li:before{content:"" counter(lst-ctn-kix_sxslfcnktzg1-4,lower-latin) ". "}.lst-kix_sxslfcnktzg1-7>li{counter-increment:lst-ctn-kix_sxslfcnktzg1-7}.lst-kix_sxslfcnktzg1-8>li:before{content:"" counter(lst-ctn-kix_sxslfcnktzg1-8,lower-roman) ". "}.lst-kix_sxslfcnktzg1-2>li:before{content:"" counter(lst-ctn-kix_sxslfcnktzg1-2,lower-roman) ". "}.lst-kix_a102oay53e4d-8>li:before{content:"\0025a0  "}.lst-kix_pmz5s3rqvha4-6>li:before{content:"" counter(lst-ctn-kix_pmz5s3rqvha4-6,decimal) ". "}.lst-kix_pmz5s3rqvha4-8>li:before{content:"" counter(lst-ctn-kix_pmz5s3rqvha4-8,lower-roman) ". "}.lst-kix_sxslfcnktzg1-0>li:before{content:"" counter(lst-ctn-kix_sxslfcnktzg1-0,decimal) ". "}.lst-kix_byq40nhaw2di-1>li:before{content:"\0025cb  "}.lst-kix_a102oay53e4d-6>li:before{content:"\0025cf  "}ol.lst-kix_pmz5s3rqvha4-5.start{counter-reset:lst-ctn-kix_pmz5s3rqvha4-5 0}.lst-kix_byq40nhaw2di-5>li:before{content:"\0025a0  "}ol.lst-kix_sxslfcnktzg1-5.start{counter-reset:lst-ctn-kix_sxslfcnktzg1-5 0}.lst-kix_pmz5s3rqvha4-0>li:before{content:"" counter(lst-ctn-kix_pmz5s3rqvha4-0,decimal) ". "}.lst-kix_byq40nhaw2di-3>li:before{content:"\0025cf  "}.lst-kix_byq40nhaw2di-7>li:before{content:"\0025cb  "}.lst-kix_pmz5s3rqvha4-4>li:before{content:"" counter(lst-ctn-kix_pmz5s3rqvha4-4,lower-latin) ". "}.lst-kix_pmz5s3rqvha4-5>li{counter-increment:lst-ctn-kix_pmz5s3rqvha4-5}ol.lst-kix_pmz5s3rqvha4-6.start{counter-reset:lst-ctn-kix_pmz5s3rqvha4-6 0}.lst-kix_pmz5s3rqvha4-2>li:before{content:"" counter(lst-ctn-kix_pmz5s3rqvha4-2,lower-roman) ". "}.lst-kix_sxslfcnktzg1-6>li:before{content:"" counter(lst-ctn-kix_sxslfcnktzg1-6,decimal) ". "}.lst-kix_sxslfcnktzg1-1>li{counter-increment:lst-ctn-kix_sxslfcnktzg1-1}ol{margin:0;padding:0}table td,table th{padding:0}.c37{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#2b2b2b;border-left-style:solid;border-bottom-width:1pt;width:585pt;border-top-color:#000000;border-bottom-style:solid}.c10{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;background-color:#2b2b2b;border-left-style:solid;border-bottom-width:0pt;width:585pt;border-top-color:#000000;border-bottom-style:solid}.c62{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:top;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;background-color:#2b2b2b;border-left-style:solid;border-bottom-width:1pt;width:229.5pt;border-top-color:#ffffff;border-bottom-style:solid}.c26{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:237pt;border-top-color:#000000;border-bottom-style:solid}.c22{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:395.2pt;border-top-color:#000000;border-bottom-style:solid}.c52{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:585.8pt;border-top-color:#000000;border-bottom-style:solid}.c3{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:190.5pt;border-top-color:#000000;border-bottom-style:solid}.c40{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:292.5pt;border-top-color:#000000;border-bottom-style:solid}.c28{margin-left:4.5pt;padding-top:0pt;list-style-position:inside;text-indent:45pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c21{margin-left:4.5pt;padding-top:3pt;list-style-position:inside;text-indent:45pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c17{-webkit-text-decoration-skip:none;color:#0366d6;font-weight:400;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:12pt;font-family:"Arial";font-style:normal}.c15{background-color:#2b2b2b;color:#808080;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Arial";font-style:normal}.c5{background-color:#2b2b2b;color:#a9b7c6;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Arial";font-style:normal}.c33{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c6{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c1{margin-left:4.5pt;padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c34{color:#24292e;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:16.5pt;font-family:"Arial";font-style:normal}.c7{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c47{color:#24292e;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:23pt;font-family:"Arial";font-style:normal}.c2{color:#24292e;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c18{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c14{margin-left:4.5pt;padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;text-align:left}.c60{text-decoration-skip-ink:none;font-size:12pt;-webkit-text-decoration-skip:none;color:#0366d6;text-decoration:underline}.c24{margin-left:4.5pt;padding-top:18pt;padding-bottom:12pt;line-height:1.0;text-align:left}.c58{padding-top:16pt;padding-bottom:12pt;line-height:1.45;page-break-after:avoid;text-align:left}.c54{font-weight:700;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c30{margin-left:4.5pt;padding-top:24pt;padding-bottom:12pt;line-height:1.25;text-align:left}.c36{font-weight:400;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c27{font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c43{padding-top:0pt;padding-bottom:12pt;line-height:1.15;text-align:left}.c8{font-size:12pt;font-family:"Roboto";color:#212121;font-weight:400}.c9{border-spacing:0;border-collapse:collapse;margin-right:auto}.c51{padding-top:0pt;padding-bottom:12pt;line-height:1.45;text-align:left}.c41{margin-left:1.5pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c31{font-size:10pt;font-family:"Consolas";color:#24292e;font-weight:400}.c50{padding-top:0pt;padding-bottom:11pt;line-height:1.45;text-align:left}.c35{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c32{margin-left:4.5pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c46{background-color:#f6f8fa;text-decoration:none;vertical-align:baseline;font-style:normal}.c4{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c12{background-color:#2b2b2b;font-size:8pt;color:#a9b7c6}.c57{background-color:#2b2b2b;font-size:8pt;color:#8888c6}.c0{background-color:#2b2b2b;font-size:8pt;color:#6a8759}.c25{background-color:#2b2b2b;font-size:8pt;color:#94558d}.c55{background-color:#f6f8fa;color:#58646d;font-size:10.5pt}.c13{background-color:#2b2b2b;font-size:8pt;color:#cc7832}.c16{background-color:#2b2b2b;font-size:8pt;color:#aa4926}.c19{background-color:#2b2b2b;font-size:8pt;color:#6897bb}.c53{color:#808080;font-size:8pt}.c39{color:#000000;font-size:16pt}.c38{padding:0;margin:0}.c23{color:inherit;text-decoration:inherit}.c48{margin-left:36pt;padding-left:0pt}.c59{max-width:585pt;padding:72pt 18pt 72pt 9pt}.c45{color:#434343;font-size:14pt}.c49{color:#24292e;font-size:12pt}.c29{orphans:2;widows:2}.c44{height:0pt}.c42{margin-left:4.5pt}.c56{height:108pt}.c20{background-color:#ffffff}.c61{height:21pt}.c11{height:11pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c20 c59"><h1 class="c30" id="h.sl8q8y4gq0tb"><span class="c47">CarND-Path-Planning-Project</span></h1><h1 class="c30" id="h.3gc3ewas5i1j"><span class="c47">Semantic Segmentation</span></h1><h3 class="c24" id="h.fjg11umz0i8q"><span class="c34">Introduction</span></h3><p class="c43 c29 c42"><span class="c2">In this project, you&#39;ll label the pixels of a road in images using a Fully Convolutional Network (FCN).</span></p><h3 class="c24" id="h.ch0qbzojsdsi"><span class="c34">Setup</span></h3><h3 class="c24" id="h.kmmkbog2bz1y"><span class="c27 c45">Frameworks and Packages</span></h3><p class="c43 c29 c42"><span class="c2">Make sure you have the following is installed:</span></p><ul class="c38 lst-kix_1rj01lbgs74w-0 start"><li class="c28"><span class="c17"><a class="c23" href="https://www.google.com/url?q=https://www.python.org/&amp;sa=D&amp;ust=1522384927654000">Python 3</a></span></li><li class="c21"><span class="c17"><a class="c23" href="https://www.google.com/url?q=https://www.tensorflow.org/&amp;sa=D&amp;ust=1522384927654000">TensorFlow</a></span></li><li class="c21"><span class="c17"><a class="c23" href="https://www.google.com/url?q=http://www.numpy.org/&amp;sa=D&amp;ust=1522384927654000">NumPy</a></span></li><li class="c21"><span class="c17"><a class="c23" href="https://www.google.com/url?q=https://www.scipy.org/&amp;sa=D&amp;ust=1522384927655000">SciPy</a></span></li></ul><h3 class="c24" id="h.h67a7u9i51oy"><span class="c27 c45">Dataset</span></h3><p class="c29 c42 c43"><span class="c49">Download the </span><span class="c60"><a class="c23" href="https://www.google.com/url?q=http://www.cvlibs.net/datasets/kitti/eval_road.php&amp;sa=D&amp;ust=1522384927655000">Kitti Road dataset</a></span><span class="c49">&nbsp;from </span><span class="c60"><a class="c23" href="https://www.google.com/url?q=http://www.cvlibs.net/download.php?file%3Ddata_road.zip&amp;sa=D&amp;ust=1522384927656000">here</a></span><span class="c49">. Extract the dataset in the </span><span class="c31">data</span><span class="c49">&nbsp;folder. This will create the folder </span><span class="c31">data_road</span><span class="c2">&nbsp;with all the training a test images.</span></p><h2 class="c24" id="h.hu03jrh0lj2d"><span class="c54 c39">Run</span></h2><p class="c43 c29 c42"><span class="c2">Run the following command to run the project:</span></p><p class="c51 c29 c42"><span class="c31 c46">python main.py</span></p><p class="c18"><span>To run this code you would need a GPU with at least 6GB of memory, because I did not have one with me I used </span><span class="c35"><a class="c23" href="https://www.google.com/url?q=http://www.floydhub.com&amp;sa=D&amp;ust=1522384927657000">floyhub</a></span><span class="c6">.</span></p><p class="c7"><span class="c6"></span></p><p class="c18"><span class="c6">To run the project under floydhub type this line in your command line after you upload your data road dataset and vgg model:</span></p><p class="c7"><span class="c6"></span></p><p class="c18"><span class="c6">floyd run --gpu --env tensorflow-1.3 --data USERNAME/datasets/data_road/1:/data_road</span></p><p class="c18"><span class="c6">--data USERNAME/datasets/pretrained_vgg/1:/pretrained_vgg &quot;python main.py&quot;</span></p><p class="c51 c29 c42 c11"><span class="c31 c46"></span></p><h3 class="c42 c58" id="h.71c4ih173a6"><span class="c45 c54">Results</span></h3><p class="c1"><span class="c33">Does the project load the pretrained vgg model?</span></p><p class="c1"><span>F</span><span class="c6">unction load_vgg is implemented correctly to load (see main.py ln54). It loads the model VGG from a SavedModel as specified by &nbsp;tags &lsquo;vgg16&rsquo; and it saves it in the specified path vgg_path and with tf.get_default_graph() we get the graph with the loaded context.</span></p><p class="c1 c11"><span class="c6"></span></p><a id="t.07784d1a38f72da83207b77d2dcfb0b6fd063d4c"></a><a id="t.0"></a><table class="c32"><tbody><tr class="c44"><td class="c62" colspan="1" rowspan="1"><p class="c1"><span class="c12">tf.saved_model.loader.load(sess</span><span class="c13">, </span><span class="c12">[</span><span class="c0">&#39;vgg16&#39;</span><span class="c12">]</span><span class="c13">, </span><span class="c5">vgg_path)</span></p><p class="c1"><span class="c5">graph = tf.get_default_graph()</span></p><p class="c1 c11"><span class="c5"></span></p><p class="c1"><span class="c12">image_input = graph.get_tensor_by_name(</span><span class="c0">&#39;image_input:0&#39;</span><span class="c5">)</span></p><p class="c1"><span class="c12">keep_prob = graph.get_tensor_by_name(</span><span class="c0">&#39;keep_prob:0&#39;</span><span class="c5">)</span></p><p class="c1"><span class="c12">layer3_out = graph.get_tensor_by_name(</span><span class="c0">&#39;layer3_out:0&#39;</span><span class="c5">)</span></p><p class="c1"><span class="c12">layer4_out = graph.get_tensor_by_name(</span><span class="c0">&#39;layer4_out:0&#39;</span><span class="c5">)</span></p><p class="c1"><span class="c12">layer7_out = graph.get_tensor_by_name(</span><span class="c0">&#39;layer7_out:0&#39;</span><span class="c12">)</span></p></td></tr></tbody></table><p class="c7"><span class="c6"></span></p><p class="c1"><span class="c33">Does the project learn the correct features from the images?</span></p><p class="c18"><span>The function layers is implemented correctly(see main.py ln78) as specified in the </span><span class="c35"><a class="c23" href="https://www.google.com/url?q=https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf&amp;sa=D&amp;ust=1522384927660000">Fully Convolutional Networks for Semantic Segmentation</a></span><span class="c6">. In order for weights to be transposed convolution layers &nbsp;are implemented using tf.layers.conv2d. After a transpose layer I applied a skip technique by adding to the output of the upper layer. The purpose of the transpose layer to match upper layer shape so I can merge weights using tf.add. </span></p><a id="t.eed9f02870b85317a8244927041917418a942c06"></a><a id="t.1"></a><table class="c32"><tbody><tr class="c44"><td class="c10" colspan="1" rowspan="1"><p class="c1"><span class="c12">kernel_initializer = tf.truncated_normal_initializer(</span><span class="c16">stddev</span><span class="c12">=</span><span class="c25">self</span><span class="c12">.init_sd)</span></p><p class="c1"><span class="c15"># 1x1 convolutions of the three layers</span></p><p class="c1"><span class="c12">conv_7 = tf.layers.conv2d(vgg_layer7_out</span><span class="c13">, </span><span class="c12">num_classes</span><span class="c13">, </span><span class="c19">1</span><span class="c13">, </span><span class="c19">1</span><span class="c13">, &nbsp;</span><span class="c16">kernel_initializer</span><span class="c12">=kernel_initializer</span><span class="c13">, </span><span class="c16">kernel_regularizer</span><span class="c5">=kernel_regularizer)</span></p><p class="c1"><span class="c12">conv_4 = tf.layers.conv2d(vgg_layer4_out</span><span class="c13">, </span><span class="c12">num_classes</span><span class="c13">, </span><span class="c19">1</span><span class="c13">, </span><span class="c19">1</span><span class="c13 c27">,</span></p><p class="c1"><span class="c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c16">kernel_initializer</span><span class="c12">=kernel_initializer</span><span class="c13">, </span><span class="c16">kernel_regularizer</span><span class="c5">=kernel_regularizer)</span></p><p class="c1"><span class="c12">conv_3 = tf.layers.conv2d(vgg_layer3_out</span><span class="c13">, </span><span class="c12">num_classes</span><span class="c13">, </span><span class="c19">1</span><span class="c13">, </span><span class="c19">1</span><span class="c27 c13">,</span></p><p class="c1"><span class="c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c16">kernel_initializer</span><span class="c12">=kernel_initializer</span><span class="c13">, </span><span class="c16">kernel_regularizer</span><span class="c5">=kernel_regularizer)</span></p><p class="c1 c11"><span class="c5"></span></p><p class="c18"><span class="c53">&nbsp;</span><span class="c27 c53"># Upsample layer 7 and add to layer 4</span></p><p class="c1"><span class="c15"># tf.layers.conv2d_transpose(inputs,filters,kernel_size,strides=(1, 1), padding=&#39;valid&#39;...)</span></p><p class="c1"><span class="c12">input = tf.layers.conv2d_transpose(conv_7</span><span class="c13">, </span><span class="c12">num_classes</span><span class="c13">, </span><span class="c19">4</span><span class="c13">, </span><span class="c19">2</span><span class="c13">, </span><span class="c0">&#39;SAME&#39;</span><span class="c27 c13">,</span></p><p class="c1"><span class="c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c16">kernel_initializer</span><span class="c12">=kernel_initializer</span><span class="c13">, </span><span class="c16">kernel_regularizer</span><span class="c5">=kernel_regularizer)</span></p><p class="c1"><span class="c12">input = tf.add(input</span><span class="c13">, </span><span class="c5">conv_4)</span></p><p class="c1 c11"><span class="c5"></span></p><p class="c1"><span class="c15"># add to layer 3</span></p><p class="c1"><span class="c12">input = tf.layers.conv2d_transpose(input</span><span class="c13">, </span><span class="c12">num_classes</span><span class="c13">, </span><span class="c19">4</span><span class="c13">, </span><span class="c19">2</span><span class="c13">, </span><span class="c0">&#39;SAME&#39;</span><span class="c27 c13">,</span></p><p class="c1"><span class="c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c16">kernel_initializer</span><span class="c12">=kernel_initializer</span><span class="c13">, </span><span class="c16">kernel_regularizer</span><span class="c5">=kernel_regularizer)</span></p><p class="c1"><span class="c12">input = tf.add(input</span><span class="c13">, </span><span class="c5">conv_3)</span></p><p class="c1 c11"><span class="c5"></span></p><p class="c1"><span class="c15"># Upsample the input and return</span></p><p class="c1"><span class="c12">input = tf.layers.conv2d_transpose(input</span><span class="c13">, </span><span class="c12">num_classes</span><span class="c13">, </span><span class="c19">16</span><span class="c13">, </span><span class="c19">8</span><span class="c13">, </span><span class="c0">&#39;SAME&#39;</span><span class="c27 c13">,</span></p><p class="c1"><span class="c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c16">kernel_initializer</span><span class="c12">=kernel_initializer</span><span class="c13">, </span><span class="c16">kernel_regularizer</span><span class="c12">=kernel_regularizer)</span></p></td></tr><tr class="c44"><td class="c10" colspan="1" rowspan="1"><p class="c7"><span class="c5"></span></p></td></tr></tbody></table><p class="c1 c11"><span class="c6"></span></p><p class="c1 c11"><span class="c5"></span></p><p class="c18"><span class="c6">To smooth out on the edges pixels I ran a series of test with kernel_regularizer and &nbsp;kernel_initializer. And as you can see in the images bellow kernel_regularizer did slightly better. </span></p><p class="c7"><span class="c5"></span></p><a id="t.e95b87504afaff215cb1e04a22cfcd5c6b8efa64"></a><a id="t.2"></a><table class="c41"><tbody><tr class="c61"><td class="c52" colspan="2" rowspan="1"><p class="c4 c29"><span class="c6">The following images were taking at 30 epoch just to identified a good way to smooth pixel on the edges. The real training model was trained with 100 epochs </span></p></td></tr><tr class="c44"><td class="c3" colspan="1" rowspan="1"><p class="c4 c29"><span class="c6">With regularizer, no kernel_initialize</span></p></td><td class="c22" colspan="1" rowspan="1"><p class="c4 c29"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 525.56px; height: 146.50px;"><img alt="" src="images/image7.png" style="width: 525.56px; height: 146.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c56"><td class="c3" colspan="1" rowspan="1"><p class="c4 c29"><span>With regularizer and kernel_initializer </span><span class="c8">vector norms</span><span class="c6">. </span></p></td><td class="c22" colspan="1" rowspan="1"><p class="c4 c42"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 513.00px; height: 142.67px;"><img alt="" src="images/image5.png" style="width: 513.00px; height: 142.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c56"><td class="c3" colspan="1" rowspan="1"><p class="c4 c29"><span>With kernel_initialize with </span><span class="c8">vector norms</span><span class="c6">, no regularizer</span></p></td><td class="c22" colspan="1" rowspan="1"><p class="c4 c42"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 513.00px; height: 142.67px;"><img alt="" src="images/image4.png" style="width: 513.00px; height: 142.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr></tbody></table><p class="c1 c11"><span class="c5"></span></p><p class="c1 c11"><span class="c6"></span></p><p class="c1 c11"><span class="c6"></span></p><p class="c1"><span class="c33">Does the project optimize the neural network?</span></p><p class="c1"><span>The function optimize is implemented correctly. </span><span class="c2 c20">We compute the softmax cross entropy between logits and labels and use an Adam algorithm optimizer to minimize the cross entropy loss.</span></p><p class="c1 c11"><span class="c2 c20"></span></p><a id="t.37483edd5c864963827a6c5c12b6813bdded772a"></a><a id="t.3"></a><table class="c32"><tbody><tr class="c44"><td class="c37" colspan="1" rowspan="1"><p class="c1"><span class="c15"># Reshape logits for computing cross entropy</span></p><p class="c1"><span class="c12">logits = tf.reshape(nn_last_layer</span><span class="c13">, </span><span class="c12">(-</span><span class="c19">1</span><span class="c13">, </span><span class="c12">num_classes)</span><span class="c13">, </span><span class="c16">name</span><span class="c12">=</span><span class="c0">&#39;logits&#39;</span><span class="c5">)</span></p><p class="c1 c11"><span class="c5"></span></p><p class="c1"><span class="c15"># Compute cross entropy and loss</span></p><p class="c1"><span class="c12">cross_entropy_logits = tf.nn.softmax_cross_entropy_with_logits(</span><span class="c16">logits</span><span class="c12">=logits</span><span class="c13">, </span><span class="c16">labels</span><span class="c5">=correct_label)</span></p><p class="c1 c11"><span class="c5"></span></p><p class="c1"><span class="c15"># All regularization terms are added to a collection called tf.GraphKeys.REGULARIZATION_LOSSES,</span></p><p class="c1"><span class="c15"># add the sum of all regularization losses to the previously calculated cross-entropy</span></p><p class="c1"><span class="c12">cross_entropy_loss = tf.reduce_mean(cross_entropy_logits) + &nbsp;</span><span class="c57">sum</span><span class="c5">(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))</span></p><p class="c1 c11"><span class="c5"></span></p><p class="c1"><span class="c15"># Training operation using the Adam optimizer</span></p><p class="c1"><span class="c5">train_op = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy_loss)</span></p><p class="c1 c11"><span class="c15"></span></p></td></tr></tbody></table><p class="c1 c11"><span class="c2 c20"></span></p><p class="c7"><span class="c6"></span></p><p class="c1"><span class="c33">Does the project train the neural network?</span></p><p class="c1"><span class="c6">The function train_nn is implemented correctly. The loss of the network is as shown below is printed while the network is training.</span></p><p class="c1 c11"><span class="c6"></span></p><a id="t.2cbd3d60fd395ef4a591027008d1b3b2a544b4d4"></a><a id="t.4"></a><table class="c9"><tbody><tr class="c44"><td class="c26" colspan="1" rowspan="1"><p class="c4 c42"><span class="c6">Below you can see the loss decreasing </span></p></td></tr><tr class="c44"><td class="c26" colspan="1" rowspan="1"><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 205.03px; height: 305.50px;"><img alt="" src="images/image6.png" style="width: 205.03px; height: 305.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr></tbody></table><p class="c29 c11 c50"><span class="c27 c55"></span></p><p class="c1"><span class="c33">Does the project train the model correctly?</span></p><p class="c1"><span class="c6">On average, the model decreases loss over time</span></p><p class="c1 c11"><span class="c6"></span></p><p class="c1"><span class="c6">Does the project use reasonable hyperparameters?</span></p><p class="c43 c29 c42"><span class="c49">In my case the optimal epoch I found with my model perform better using a batch size of 10 and loose was did not reduced after 100 epochs. </span></p><p class="c1 c11"><span class="c6"></span></p><p class="c1"><span class="c33">Does the project correctly label the road?</span></p><p class="c1"><span class="c6">The project labels most pixels of roads close to the best solution. The model doesn&#39;t have to predict correctly all the images, just most of them. As you can see in the images bellow this model is labeling more than 80% of the road and label no more than 20% of non-road pixels as road. </span></p><p class="c1 c11"><span class="c6"></span></p><a id="t.34c968869fbbdaac8fff0fec79919d98042a1192"></a><a id="t.5"></a><table class="c32"><tbody><tr class="c44"><td class="c40" colspan="1" rowspan="1"><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 373.00px; height: 104.00px;"><img alt="" src="images/image2.png" style="width: 373.00px; height: 104.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c40" colspan="1" rowspan="1"><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 373.00px; height: 104.00px;"><img alt="" src="images/image8.png" style="width: 373.00px; height: 104.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c44"><td class="c40" colspan="1" rowspan="1"><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 373.00px; height: 104.00px;"><img alt="" src="images/image3.png" style="width: 373.00px; height: 104.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c40" colspan="1" rowspan="1"><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 373.00px; height: 104.00px;"><img alt="" src="images/image1.png" style="width: 373.00px; height: 104.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr></tbody></table><p class="c1 c11"><span class="c6"></span></p><p class="c1 c11"><span class="c6"></span></p><hr><p class="c51 c29 c42 c11"><span class="c31 c46"></span></p><p class="c29 c42 c11 c51"><span class="c31 c46"></span></p><p class="c43 c29 c42 c11"><span class="c2"></span></p><h2 class="c14" id="h.kpumfxhu7sl8"><span class="c27 c39">References:</span></h2><ul class="c38 lst-kix_a102oay53e4d-0 start"><li class="c18 c48"><span>Udacity Self-Driving Car <br>The link for the frozen VGG16 model is hardcoded into helper.py. The model can be found </span><span class="c35 c36"><a class="c23" href="https://www.google.com/url?q=https://s3-us-west-1.amazonaws.com/udacity-selfdrivingcar/vgg.zip&amp;sa=D&amp;ust=1522384927678000">here</a></span></li><li class="c18 c48"><span>The model is not vanilla VGG16, but a fully convolutional version, which already contains the 1x1 convolutions to replace the fully connected layers. Please see this </span><span class="c35"><a class="c23" href="https://www.google.com/url?q=https://discussions.udacity.com/t/here-is-some-advice-and-clarifications-about-the-semantic-segmentation-project/403100/8?u%3Dsubodh.malgonde&amp;sa=D&amp;ust=1522384927679000">forum post</a></span><span class="c6">&nbsp;for more information. A summary of additional points, follow.</span></li><li class="c18 c48"><span class="c6">The original FCN-8s was trained in stages. The authors later uploaded a version that was trained all at once to their GitHub repo. The version in the GitHub repo has one important difference: The outputs of pooling layers 3 and 4 are scaled before they are fed into the 1x1 convolutions. As a result, some students have found that the model learns much better with the scaling layers included. The model may not converge substantially faster, but may reach a higher IoU and accuracy.</span></li><li class="c18 c48"><span class="c6">When adding l2-regularization, setting a regularizer in the arguments of the tf.layers is not enough. Regularization loss terms must be manually added to your loss function. otherwise regularization is not implemented.</span></li></ul><p class="c1 c11"><span><br></span></p></body></html>